{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd8cf1-70df-4961-afed-844af8813a41",
   "metadata": {},
   "source": [
    "# Imports & preparatory steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e53c2-dbd2-40b3-aa5f-76fe1d366f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# Check the number of CPUs\n",
    "# $PBS_NUM_PPN vs $OMP_NUM_THREADS?\n",
    "N_CPUS = int(os.environ[\"PBS_NUM_PPN\"])\n",
    "\n",
    "# Limit CPU operation in pytorch to `N_CPUS`\n",
    "torch.set_num_threads(N_CPUS)\n",
    "torch.set_num_interop_threads(N_CPUS)\n",
    "\n",
    "# Set username\n",
    "USER = os.environ[\"USER\"]\n",
    "\n",
    "# Check free port\n",
    "def get_free_port(ports):\n",
    "    import socket\n",
    "    for port in ports:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            if s.connect_ex((\"localhost\", port)) != 0:\n",
    "                break\n",
    "    return port\n",
    "\n",
    "port = get_free_port(range(29500, 29526))\n",
    "\n",
    "# Prepare for multi-gpu training\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = f\"{port}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29b983-7dcd-4cdc-9577-c870bd9b4169",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b9f3d-cfc4-42b5-89c2-6009f44c3131",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# General params\n",
    "run_name = \"test\"\n",
    "\n",
    "train_params =  {\n",
    "    \"log_interval\": 50,\n",
    "    \"eval_interval\": 100,\n",
    "    \"seed\": 1234,\n",
    "    \"epochs\": 2000,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"betas\": [0.8, 0.99],\n",
    "    \"eps\": 1e-9,\n",
    "    \"batch_size\": 16,\n",
    "    \"fp16_run\": False,\n",
    "    \"lr_decay\": 0.999875,\n",
    "    \"segment_size\": 8192,\n",
    "    \"init_lr_ratio\": 1,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"c_mel\": 45,\n",
    "    \"c_kl\": 1.0\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"use_mel_posterior_encoder\": True,\n",
    "    \"dataset_path\": f\"/storage/plzen4-ntis/home/{USER}/experimenty/vits2_cz/datasets/NeuOl\",\n",
    "    \"training_files\": \"train0.ph-redu.epa.p3b0.csv\",\n",
    "    \"validation_files\": \"val0.ph-redu.epa.p3b0.csv\",\n",
    "    \"text_cleaners\":[\"english_cleaners2\"],\n",
    "    \"max_wav_value\": 32768.0,\n",
    "    \"sampling_rate\": 24000,\n",
    "    \"filter_length\": 1024,\n",
    "    \"hop_length\": 256,\n",
    "    \"win_length\": 1024,\n",
    "    \"n_mel_channels\": 80,\n",
    "    \"mel_fmin\": 0.0,\n",
    "    \"mel_fmax\": None,\n",
    "    \"add_blank\": False,\n",
    "    \"n_speakers\": 0,\n",
    "    \"cleaned_text\": True,\n",
    "    \"eval_audio_folder\": \"eval_audios\",\n",
    "    \"characters\": \"\\\\ACDEFGHIJLMNOPQRSTUWYZabcdefghijklmnopqrstuvwxyz@#$*%Ç\",\n",
    "    \"punctuation\": \"!,-.:;–/()?ˈ„“”\\\"‚‘’ˌː…¡¿«» \" ,\n",
    "    \"pad\": \"_\",\n",
    "    \"num_workers\": 2,\n",
    "    \"min_text_len\": 5,\n",
    "    \"max_text_len\": 999,\n",
    "    \"min_audio_len\": 8192,\n",
    "    \"seed\": 1234,\n",
    "  }\n",
    "\n",
    "model = {\n",
    "  \"use_mel_posterior_encoder\": True,\n",
    "  \"use_transformer_flows\": True,\n",
    "  \"transformer_flow_type\": \"pre_conv\",\n",
    "  \"use_spk_conditioned_encoder\": False,\n",
    "  \"use_noise_scaled_mas\": True,\n",
    "  \"use_duration_discriminator\": True,\n",
    "  \"duration_discriminator_type\": \"dur_disc_1\",\n",
    "  \"inter_channels\": 192,\n",
    "  \"hidden_channels\": 192,\n",
    "  \"filter_channels\": 768,\n",
    "  \"n_heads\": 2,\n",
    "  \"n_layers\": 6,\n",
    "  \"kernel_size\": 3,\n",
    "  \"p_dropout\": 0.1,\n",
    "  \"resblock\": \"1\",\n",
    "  \"resblock_kernel_sizes\": [3,7,11],\n",
    "  \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
    "  \"upsample_rates\": [8,8,2,2],\n",
    "  \"upsample_initial_channel\": 512,\n",
    "  \"upsample_kernel_sizes\": [16,16,4,4],\n",
    "  \"n_layers_q\": 3,\n",
    "  \"use_spectral_norm\": False,\n",
    "  \"use_sdp\": True\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8b0f2-629c-4d7f-be92-18ab310a4015",
   "metadata": {
    "tags": [
     "injected_parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273fdc-b422-47d6-8358-f057a0a1a8a0",
   "metadata": {},
   "source": [
    "# Copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d5828-e730-4bd8-8ae3-9f6b5ba3f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COPY_TO_SCRATCH:\n",
    "    # Copy dataset\n",
    "    # Prepare dataset dir in the scratch\n",
    "    dataset_scratch = os.path.join(os.environ[\"SCRATCHDIR\"], os.path.basename(data[\"dataset_path\"]))\n",
    "    # Copy dataset to local scratch\n",
    "    print(f\"> Copying data to local scratch: {dataset_scratch}\")\n",
    "    shutil.copytree(data[\"dataset_path\"], dataset_scratch)\n",
    "    # Store the scratch dataset so that it is used for training\n",
    "    data[\"dataset_path\"] = dataset_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b88a2-3ab7-45a1-a0e9-d5cd98ed226c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b746fe4-9f72-43a6-8bd0-da5fd7200a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from torch import __version__ as torch_version\n",
    "import torch.multiprocessing as mp\n",
    "from platform import python_version\n",
    "from utils import HParams\n",
    "# Trainer: Where the ✨️ happens.\n",
    "import train\n",
    "\n",
    "assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\" > Computational resources...\")\n",
    "print(f\" | > Localhost port: {port}\")\n",
    "print(f\" | > Number of CPUs: {N_CPUS}\")\n",
    "print(f\" | > Number of GPUs: {n_gpus}\")\n",
    "print(\" > Python & module versions...\")\n",
    "print(f\" | > Python:    {python_version()}\")\n",
    "print(f\" | > PyTorch:   {torch_version}\")\n",
    "\n",
    "# Make up the hyperparameters from individual settings\n",
    "hps = {\n",
    "    \"train\": train_params,\n",
    "    \"data\": data,\n",
    "    \"model\": model,\n",
    "}\n",
    "\n",
    "# Prepare dir for saving traning checkpoint/model files\n",
    "model_dir = os.path.join(f\"./logs/{run_name}\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# Save JSON config to model dir\n",
    "config_save_path = os.path.join(model_dir, \"config.json\")\n",
    "with open(config_save_path, \"w\") as json_file:\n",
    "    json.dump(hps, json_file, indent=4)\n",
    "\n",
    "# Prepare hyperparameters and add model dir\n",
    "hps = HParams(**hps)\n",
    "hps.model_dir = model_dir\n",
    "\n",
    "# Start multi-gpu training\n",
    "mp.spawn(\n",
    "    train.run,\n",
    "    nprocs=n_gpus,\n",
    "    args=(n_gpus, hps,),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddb788-d61f-4dfe-acc9-66c6546feb3f",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8a1c-59ee-41e0-8d15-bcf7dbe905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COPY_TO_SCRATCH:\n",
    "    shutil.rmtree(dataset_scratch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
