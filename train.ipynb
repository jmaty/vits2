{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd8cf1-70df-4961-afed-844af8813a41",
   "metadata": {},
   "source": [
    "# Imports & preparatory steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8e53c2-dbd2-40b3-aa5f-76fe1d366f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# Check the number of CPUs\n",
    "# $PBS_NUM_PPN vs $OMP_NUM_THREADS?\n",
    "N_CPUS = int(os.environ[\"PBS_NUM_PPN\"])\n",
    "\n",
    "# Limit CPU operation in pytorch to `N_CPUS`\n",
    "torch.set_num_threads(N_CPUS)\n",
    "torch.set_num_interop_threads(N_CPUS)\n",
    "\n",
    "# Set username\n",
    "USER = os.environ[\"USER\"]\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"6060\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29b983-7dcd-4cdc-9577-c870bd9b4169",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952e8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284b9f3d-cfc4-42b5-89c2-6009f44c3131",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# General params\n",
    "run_name = \"test\"\n",
    "\n",
    "train_params =  {\n",
    "    \"log_interval\": 50,\n",
    "    \"eval_interval\": 100,\n",
    "    \"seed\": 1234,\n",
    "    \"epochs\": 2000,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"betas\": [0.8, 0.99],\n",
    "    \"eps\": 1e-9,\n",
    "    \"batch_size\": 16,\n",
    "    \"fp16_run\": False,\n",
    "    \"lr_decay\": 0.999875,\n",
    "    \"segment_size\": 8192,\n",
    "    \"init_lr_ratio\": 1,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"c_mel\": 45,\n",
    "    \"c_kl\": 1.0\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"use_mel_posterior_encoder\": True,\n",
    "    \"dataset_path\": f\"/storage/plzen4-ntis/home/{USER}/experimenty/vits2_cz/datasets/NeuOl\",\n",
    "    \"training_files\": \"train0.ph-redu.epa.p3b0.csv\",\n",
    "    \"validation_files\": \"val0.ph-redu.epa.p3b0.csv\",\n",
    "    \"text_cleaners\":[\"english_cleaners2\"],\n",
    "    \"max_wav_value\": 32768.0,\n",
    "    \"sampling_rate\": 24000,\n",
    "    \"filter_length\": 1024,\n",
    "    \"hop_length\": 256,\n",
    "    \"win_length\": 1024,\n",
    "    \"n_mel_channels\": 80,\n",
    "    \"mel_fmin\": 0.0,\n",
    "    \"mel_fmax\": None,\n",
    "    \"add_blank\": False,\n",
    "    \"n_speakers\": 0,\n",
    "    \"cleaned_text\": True,\n",
    "    \"eval_audio_folder\": \"eval_audios\",\n",
    "    \"characters\": \"\\\\ACDEFGHIJLMNOPQRSTUWYZabcdefghijklmnopqrstuvwxyz@#$*%Ç\",\n",
    "    \"punctuation\": \"!,-.:;–/()?ˈ„“”\\\"‚‘’ˌː…¡¿«» \" ,\n",
    "    \"pad\": \"_\",\n",
    "    \"num_workers\": 2\n",
    "  }\n",
    "\n",
    "model = {\n",
    "  \"use_mel_posterior_encoder\": True,\n",
    "  \"use_transformer_flows\": True,\n",
    "  \"transformer_flow_type\": \"pre_conv\",\n",
    "  \"use_spk_conditioned_encoder\": False,\n",
    "  \"use_noise_scaled_mas\": True,\n",
    "  \"use_duration_discriminator\": True,\n",
    "  \"duration_discriminator_type\": \"dur_disc_1\",\n",
    "  \"inter_channels\": 192,\n",
    "  \"hidden_channels\": 192,\n",
    "  \"filter_channels\": 768,\n",
    "  \"n_heads\": 2,\n",
    "  \"n_layers\": 6,\n",
    "  \"kernel_size\": 3,\n",
    "  \"p_dropout\": 0.1,\n",
    "  \"resblock\": \"1\",\n",
    "  \"resblock_kernel_sizes\": [3,7,11],\n",
    "  \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
    "  \"upsample_rates\": [8,8,2,2],\n",
    "  \"upsample_initial_channel\": 512,\n",
    "  \"upsample_kernel_sizes\": [16,16,4,4],\n",
    "  \"n_layers_q\": 3,\n",
    "  \"use_spectral_norm\": False,\n",
    "  \"use_sdp\": True\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b8b0f2-629c-4d7f-be92-18ab310a4015",
   "metadata": {
    "tags": [
     "injected_parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273fdc-b422-47d6-8358-f057a0a1a8a0",
   "metadata": {},
   "source": [
    "# Copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075d5828-e730-4bd8-8ae3-9f6b5ba3f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COPY_TO_SCRATCH:\n",
    "    # Copy dataset\n",
    "    # Prepare dataset dir in the scratch\n",
    "    dataset_scratch = os.path.join(os.environ[\"SCRATCHDIR\"], data[\"dataset_path\"])\n",
    "    print(f\"> Local scratch data dir: {dataset_scratch}\")\n",
    "\n",
    "    # Copy dataset to local scratch\n",
    "    if not os.path.isfile(dataset_scratch):\n",
    "        shutil.copy(path_to_datadir, dataset_scratch, follow_symlinks=True)\n",
    "    # Store the scratch dataset so that it is used for training\n",
    "    data[\"dataset_path\"] = dataset_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a82a2f",
   "metadata": {},
   "source": [
    "# Set path to training framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6ca9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set path to (modified) Coqui-TTS\n",
    "#sys.path.insert(0, coqui_path)\n",
    "## Set path to (modified) Coqui-Trainer\n",
    "#sys.path.insert(0, trainer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b88a2-3ab7-45a1-a0e9-d5cd98ed226c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b746fe4-9f72-43a6-8bd0-da5fd7200a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:jax._src.path:etils.epath was not found. Using pathlib for file I/O.\n",
      " > Computational resources...\n",
      " | > Number of CPUs: 1\n",
      " | > Number of GPUs: 1\n",
      " > Python & module versions...\n",
      " | > Python:    3.10.12\n",
      " | > PyTorch:   2.1.2+cu121\n",
      "INFO:test:{'train': {'log_interval': 50, 'eval_interval': 100, 'seed': 1234, 'epochs': 2000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 16, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'use_mel_posterior_encoder': True, 'dataset_path': '/storage/plzen4-ntis/home/jmatouse/experimenty/vits2_cz/datasets/NeuOl', 'training_files': 'train0.ph-redu.epa.p3b0.csv', 'validation_files': 'val0.ph-redu.epa.p3b0.csv', 'text_cleaners': ['english_cleaners2'], 'max_wav_value': 32768.0, 'sampling_rate': 24000, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': False, 'n_speakers': 0, 'cleaned_text': True, 'eval_audio_folder': 'eval_audios', 'characters': '\\\\ACDEFGHIJLMNOPQRSTUWYZabcdefghijklmnopqrstuvwxyz@#$*%Ç', 'punctuation': '!,-.:;–/()?ˈ„“”\"‚‘’ˌː…¡¿«» ', 'pad': '_', 'num_workers': 2}, 'model': {'use_mel_posterior_encoder': True, 'use_transformer_flows': True, 'transformer_flow_type': 'pre_conv', 'use_spk_conditioned_encoder': False, 'use_noise_scaled_mas': True, 'use_duration_discriminator': True, 'duration_discriminator_type': 'dur_disc_1', 'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'use_sdp': True}, 'model_dir': './logs/test'}\n",
      "Using mel posterior encoder for VITS2\n",
      "Using transformer flows pre_conv for VITS2\n",
      "Using normal encoder for VITS1\n",
      "Using noise scaled MAS for VITS2\n",
      "Using duration_discriminator dur_disc_1 for VITS2\n",
      "./logs/test/G_300-34.pth\n",
      "INFO:test:Loaded checkpoint './logs/test/G_300-34.pth' (iteration 34)\n",
      "./logs/test/D_300-34.pth\n",
      "INFO:test:Loaded checkpoint './logs/test/D_300-34.pth' (iteration 34)\n",
      "./logs/test/DUR_300-34.pth\n",
      "INFO:test:Loaded checkpoint './logs/test/DUR_300-34.pth' (iteration 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Loading train data:  33%|███▎      | 3/9 [00:28<00:48,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:Train Epoch: 34 [33%]\n",
      "INFO:test:[2.7217400074005127, 2.0024616718292236, 2.0019309520721436, 29.149261474609375, 2.802926778793335, 2.926793336868286, 300, 0.00019912685682091382]\n",
      "DEBUG:matplotlib:matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=/storage/plzen4-ntis/home/jmatouse/.config/matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is linux\n",
      "INFO:test:Saving eval audio at epoch 34, step 300\n",
      "INFO:test:Saving model and optimizer state at iteration 34 to ./logs/test/G_300-34.pth\n",
      "INFO:test:Saving model and optimizer state at iteration 34 to ./logs/test/D_300-34.pth\n",
      "INFO:test:Saving model and optimizer state at iteration 34 to ./logs/test/DUR_300-34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [01:07<00:00,  7.54s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 34 (steps: 306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 35 (steps: 315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.62s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 36 (steps: 324)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.57s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 37 (steps: 333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.57s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 38 (steps: 342)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data:  89%|████████▉ | 8/9 [00:13<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:Train Epoch: 39 [89%]\n",
      "INFO:test:[2.613800048828125, 2.0777127742767334, 2.3820409774780273, 26.742374420166016, 2.730661392211914, 3.121246099472046, 350, 0.00019900243364508313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:15<00:00,  1.72s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 39 (steps: 351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.62s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 40 (steps: 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.63s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 41 (steps: 369)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:15<00:00,  1.68s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 42 (steps: 378)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.58s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 43 (steps: 387)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.56s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 44 (steps: 396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data:  44%|████▍     | 4/9 [00:10<00:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:Train Epoch: 45 [44%]\n",
      "INFO:test:[2.6554269790649414, 2.1317427158355713, 3.1085214614868164, 26.795900344848633, 2.603837251663208, 2.630241632461548, 400, 0.00019885322845327182]\n",
      "INFO:test:Saving eval audio at epoch 45, step 400\n",
      "INFO:test:Saving model and optimizer state at iteration 45 to ./logs/test/G_400-45.pth\n",
      "INFO:test:Saving model and optimizer state at iteration 45 to ./logs/test/D_400-45.pth\n",
      "INFO:test:Saving model and optimizer state at iteration 45 to ./logs/test/DUR_400-45.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:28<00:00,  3.19s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed ./logs/test/G_100-12.pth\n",
      "removed ./logs/test/D_100-12.pth\n",
      "removed ./logs/test/DUR_100-12.pth\n",
      "INFO:test:====> Epoch: 45 (steps: 405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.60s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 46 (steps: 414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.59s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 47 (steps: 423)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.63s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 48 (steps: 432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.60s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 49 (steps: 441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.59s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 50 (steps: 450)\n",
      "INFO:test:Train Epoch: 51 [0%]\n",
      "INFO:test:[2.4663612842559814, 2.180588722229004, 3.0097405910491943, 25.118480682373047, 2.6429929733276367, 2.596942186355591, 450, 0.00019870413513039026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 9/9 [00:14<00:00,  1.62s/it]\n",
      "Loading train data:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:test:====> Epoch: 51 (steps: 459)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from torch import __version__ as torch_version\n",
    "import torch.multiprocessing as mp\n",
    "from platform import python_version\n",
    "from utils import HParams\n",
    "# Trainer: Where the ✨️ happens.\n",
    "import train\n",
    "\n",
    "assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\" > Computational resources...\")\n",
    "print(f\" | > Number of CPUs: {N_CPUS}\")\n",
    "print(f\" | > Number of GPUs: {n_gpus}\")\n",
    "print(\" > Python & module versions...\")\n",
    "print(f\" | > Python:    {python_version()}\")\n",
    "print(f\" | > PyTorch:   {torch_version}\")\n",
    "\n",
    "# Make up the hyperparameters from individual settings\n",
    "hps = {\n",
    "    \"train\": train_params,\n",
    "    \"data\": data,\n",
    "    \"model\": model,\n",
    "}\n",
    "\n",
    "model_dir = os.path.join(f\"./logs/{run_name}\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "config_save_path = os.path.join(model_dir, \"config.json\")\n",
    "with open(config_save_path, \"w\") as json_file:\n",
    "    json.dump(hps, json_file)\n",
    "\n",
    "hps = HParams(**hps)\n",
    "hps.model_dir = model_dir\n",
    "\n",
    "mp.spawn(\n",
    "    train.run,\n",
    "    nprocs=n_gpus,\n",
    "    args=(n_gpus, hps,),\n",
    ")\n",
    "\n",
    "# train.run(0, 1, hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddb788-d61f-4dfe-acc9-66c6546feb3f",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8a1c-59ee-41e0-8d15-bcf7dbe905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COPY_TO_SCRATCH:\n",
    "    os.unlink(dataset_scratch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
